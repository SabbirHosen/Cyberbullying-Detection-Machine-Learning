{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cyberbullying Detection trained model Loader.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "id": "MDFkrB5oxNHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "NLzq5OOKwMpU",
        "outputId": "8cad1cdc-e1c1-45c6-b6e5-6142847dee84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pickle\n",
        "import io\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, precision_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from emoji import emojize\n",
        "import emoji\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import re,string, nltk\n",
        "import nltk\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\")\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = pickle.load(open(\"vectorizer.pickle\", \"rb\"))\n",
        "model = pickle.load(open(\"model.pickle\", \"rb\"))"
      ],
      "metadata": {
        "id": "i3DsCvKtwSw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = ['Bro. U gotta chill RT @CHILLShrammy: Dog FUCK KP that dumb nigger bitch lmao']"
      ],
      "metadata": {
        "id": "A3XFjmqMwk8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0] = x[0].replace(r\"http\\S+\",\" \")\n",
        "x[0]  = x[0].replace(r\"http\",\" \")\n",
        "x[0]  = x[0].replace(r\"@\",\"at\")\n",
        "x[0]  = x[0].replace(\"#[A-Za-z0-9_]+\", ' ')\n",
        "x[0]  = x[0].replace(r\"[^A-Za-z(),!?@\\'\\\"_\\n]\",\" \")\n",
        "x[0]  = x[0].lower()"
      ],
      "metadata": {
        "id": "Hex_Ew34woLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-_DihdXcwq2R",
        "outputId": "5cd3dc65-b4f4-4a3f-96a8-d3251e917b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bro. u gotta chill rt atchillshrammy: dog fuck kp that dumb nigger bitch lmao'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Lemmmatizer to remove tenses from texts.\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "STOPWORDS.update(['rt', 'mkr', 'didn', 'bc', 'n', 'm', \n",
        "                  'im', 'll', 'y', 've', 'u', 'ur', 'don', \n",
        "                  'p', 't', 's', 'aren', 'kp', 'o', 'kat', \n",
        "                  'de', 're', 'amp', 'will'])\n",
        "corpus = []\n",
        "def preprocess_tweet(tweet):\n",
        "    tweet = re.sub(r\"won\\'t\", \"will not\", tweet)\n",
        "    tweet = re.sub(r\"can\\'t\", \"can not\", tweet)\n",
        "    tweet = re.sub(r\"n\\'t\", \" not\", tweet)\n",
        "    tweet = re.sub(r\"\\'re\", \" are\", tweet)\n",
        "    tweet = re.sub(r\"\\'s\", \" is\", tweet)\n",
        "    tweet = re.sub(r\"\\'d\", \" would\",tweet)\n",
        "    tweet = re.sub(r\"\\'ll\", \" will\", tweet)\n",
        "    tweet = re.sub(r\"\\'t\", \" not\", tweet)\n",
        "    tweet = re.sub(r\"\\'ve\", \" have\", tweet)\n",
        "    tweet = re.sub(r\"\\'m\", \" am\", tweet)\n",
        "    tweet = re.sub('[^a-zA-Z]',' ',tweet)\n",
        "    tweet = re.sub(emoji.get_emoji_regexp(),\"\",tweet)\n",
        "    tweet = re.sub(r'[^\\x00-\\x7f]','',tweet)\n",
        "    tweet = \" \".join([stemmer.stem(word) for word in tweet.split()])\n",
        "    tweet = [lemmatizer.lemmatize(word) for word in tweet.split() if not word in set(STOPWORDS)]\n",
        "    tweet = ' '.join(tweet)\n",
        "    return tweet"
      ],
      "metadata": {
        "id": "IXVBXIYewwz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new = tfidf.transform([x[0]])"
      ],
      "metadata": {
        "id": "8dqnK5BNw_p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model.predict(new)"
      ],
      "metadata": {
        "id": "vlRNUaE-xCS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5_l16AexYZu",
        "outputId": "e2c9c74a-23fb-4e6d-9af9-3ad2b5683e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I3sx8VGl1zkt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}